# Docker Compose Configuration
# This file is used by docker-compose for variable substitution in docker-compose.yml
# Copy this file to .env and customize as needed

# ──────────────────────────────────────────────────────────────────
# Port Configuration
# ──────────────────────────────────────────────────────────────────
# Host port mapping (container always runs on 11235 internally)
HOST_PORT=11235

# ──────────────────────────────────────────────────────────────────
# Image Selection
# ──────────────────────────────────────────────────────────────────
# Use pre-built image from Docker Hub (recommended)
# IMAGE=unclecode/crawl4ai:latest
# TAG=latest

# ──────────────────────────────────────────────────────────────────
# Build Configuration (only applies when building locally)
# ──────────────────────────────────────────────────────────────────

# INSTALL_TYPE: Feature set for the installation
#   - default: Basic installation (~2-3GB image)
#             Includes: JsonCssExtractionStrategy, JsonXPathExtractionStrategy,
#                      LLMExtractionStrategy (API-based, no local ML)
#             Best for: Standard web crawling, structured extraction, LLM-based extraction
#
#   - all: Full installation with ML dependencies (~6-8GB image)
#         Adds: PyTorch, transformers, sentence-transformers, scikit-learn, NLTK
#         Enables: CosineStrategy (semantic clustering), local transformer models
#         Best for: Advanced ML-based extraction, semantic content analysis
#
#   - torch: PyTorch + scikit-learn + NLTK (no transformers)
#   - transformer: Transformers + sentence-transformers (no PyTorch)
#
INSTALL_TYPE=default

# ENABLE_GPU: Enable NVIDIA CUDA support for GPU acceleration
#   - false: CPU-only (works on all platforms)
#   - true: Adds CUDA toolkit (AMD64/x86_64 only, requires NVIDIA GPU)
#
# Note: GPU support only available on AMD64 architecture
#       ARM64 (Apple Silicon) will skip GPU installation
#
ENABLE_GPU=false